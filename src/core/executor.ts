import { getSchoolConfig } from "../mapping/localAdapter";
import { fetchData } from "../dataImport";
import { transformAndValidate } from "./pipeline";
import { writeToInternalJavaService } from "../saveData/javaService";
import { saveImportResultToDb } from "../utils/dbLogger"; // ä¿®æ”¹ä¸º DB Logger
import { baseConfig, getEndpointForEntity } from "../saveData/config";
import { EntityType } from "../types";

/**
 * æ‰§è¡Œæ ¸å¿ƒåŒæ­¥é€»è¾‘çš„å‡½æ•°
 * æ”¯æŒè‡ªåŠ¨åˆ†é¡µå¾ªç¯ï¼šæŠ“å–ä¸€é¡µ -> è½¬æ¢ä¸€é¡µ -> å†™å…¥ä¸€é¡µ
 */
export async function runSyncTask(
  tenantId: string,
  entityType: EntityType,
  environment: string = "dev",
  providedTraceId?: string // æ–°å¢ï¼šå¯é€‰çš„å¤–éƒ¨ traceId
) {
  console.log(
    `\n>>> [Executor] Starting Sync: Tenant=${tenantId}, Entity=${entityType}, Env=${environment}`
  );

  // å¿…é¡»åœ¨ try/catch ä¹‹å¤–å®šä¹‰ï¼Œå¦åˆ™ catch ä¸­æ— æ³•å¼•ç”¨ï¼Œå¯¼è‡´çŠ¶æ€æ— æ³•è½åº“
  const taskTraceId = providedTraceId || `task_${Date.now()}`;

  let totalProcessed = 0;
  let totalWritten = 0;
  let totalFailed = 0;
  let allCollectedRecords: any[] = [];
  let rawDataSample: any[] = [];
  let lastWriteFailure: any = null; // æ–°å¢ï¼šä¿å­˜æœ€åçš„å†™å…¥å¤±è´¥è¯¦æƒ…
  let finalStages = {
    fetch: { total: 0, status: "success" },
    transform: { success: 0, failed: 0 },
    write: { success: 0, failed: 0 },
  };

  let page = 1;
  let offset = 0;
  let hasMore = true;

  try {
    const config = await getSchoolConfig(tenantId, entityType);

    // --- ä¿®æ”¹ï¼šä½¿ç”¨å¤–éƒ¨ä¼ å…¥æˆ–æ–°ç”Ÿæˆçš„ traceId ---
    await saveImportResultToDb(tenantId, entityType, taskTraceId, [], {
      fetch: { total: 0, status: "running" },
      transform: { success: 0, failed: 0 },
      write: { success: 0, failed: 0 },
    });

    while (hasMore) {
      // 1. å‡†å¤‡é…ç½®
      const currentConfig = { ...config };
      if (
        currentConfig.dataSource.type === "api" &&
        currentConfig.dataSource.config.pagination
      ) {
        currentConfig.dataSource.config.pagination.startPage = page;
      } else if (currentConfig.dataSource.type === "db") {
        currentConfig.dataSource.config.offset = offset;
      }

      // 2. æŠ“å–æ•°æ®
      const envelope = await fetchData(currentConfig);
      const rawData = envelope.rawData;
      const currentBatchSize = Array.isArray(rawData)
        ? rawData.length
        : rawData
        ? 1
        : 0;

      if (currentBatchSize === 0) {
        console.log(`[Executor] ğŸ No more data found.`);
        break;
      }

      // é‡‡é›†åŸå§‹æ•°æ®æ ·æœ¬ (é™åˆ¶é‡‡é›†å‰ 500 æ¡ï¼Œé˜²æ­¢æ•°æ®åº“è¶…é™ï¼ŒåŒæ—¶ä¹Ÿè¦†ç›–äº†å¤§å¤šæ•°åœºæ™¯)
      if (rawDataSample.length < 500) {
        const sample = Array.isArray(rawData) ? rawData : [rawData];
        rawDataSample.push(...sample);
        if (rawDataSample.length > 500) {
          rawDataSample = rawDataSample.slice(0, 500);
        }
      }

      // 3. è½¬æ¢ä¸æ ¡éªŒ
      const {
        allRecords: batchRecords,
        successCount,
        failedCount,
      } = await transformAndValidate(envelope, currentConfig);

      allCollectedRecords.push(...batchRecords);
      finalStages.fetch.total += currentBatchSize;
      finalStages.transform.success += successCount;
      finalStages.transform.failed += failedCount;

      // 4. å†™å…¥ Java æœåŠ¡
      const dataToWrite = batchRecords
        .filter((r) => r._importStatus === "success")
        .map(({ _importStatus, _importError, _metadata, ...rest }) => rest);

      if (dataToWrite.length > 0) {
        const javaResult = await writeToInternalJavaService(dataToWrite, {
          batchSize:
            config.batchConfig.batchSize || baseConfig.DEFAULT_BATCH_SIZE,
          concurrency: Math.max(1, baseConfig.MAX_GLOBAL_CONCURRENCY / 2),
          javaEndpoint: await getEndpointForEntity(
            config.entityType,
            environment
          ),
          authToken: config.javaAuthToken,
          entityType: config.entityType,
        });

        if (javaResult.debugInfo) {
          lastWriteFailure = javaResult.debugInfo;
        }

        // ğŸš¨ æ ¸å¿ƒï¼šå¦‚æœ Java å†™å…¥æœ‰å¤±è´¥ï¼Œå°†åŸå› åŒæ­¥åˆ° batchRecords ä¸­ï¼Œä½†ä¸å†ä¿®æ”¹ transform çš„ç»Ÿè®¡è®¡æ•°
        if (javaResult.errors.length > 0) {
          javaResult.errors.forEach((javaErr) => {
            const record = batchRecords.find((r) => r.id === javaErr.id);
            if (record) {
              record._importStatus = "failed";
              record._importError = `[Javaä¸šåŠ¡] ${javaErr.message}`;
            }
          });
        }

        totalWritten += javaResult.success;
        finalStages.write.success += javaResult.success;
        finalStages.write.failed += javaResult.failed;
      }

      totalProcessed += currentBatchSize;
      totalFailed += failedCount;

      console.log(
        `[Executor] ğŸ“¦ Batch Finished: Page ${page}, Processed ${currentBatchSize}, Valid ${successCount}`
      );

      // 5. åˆ†é¡µæ§åˆ¶
      if (
        currentConfig.dataSource.type === "api" &&
        currentConfig.dataSource.config.pagination
      ) {
        page++;
        if (
          currentBatchSize < currentConfig.dataSource.config.pagination.pageSize
        ) {
          hasMore = false;
        }
      } else if (currentConfig.dataSource.type === "db") {
        const dbBatchSize = currentConfig.dataSource.config.batchSize || 1000;
        offset += dbBatchSize;
        if (currentBatchSize < dbBatchSize) {
          hasMore = false;
        }
      } else {
        hasMore = false;
      }

      // Mock ä¿æŠ¤
      if (
        config.dataSource.type === "api" &&
        config.dataSource.config.url.includes("example.com")
      ) {
        hasMore = false;
      }
    }

    // 6. æœ€ç»ˆæ—¥å¿—ä¿å­˜åˆ°æ•°æ®åº“
    await saveImportResultToDb(
      tenantId,
      entityType,
      taskTraceId,
      allCollectedRecords,
      finalStages,
      rawDataSample,
      lastWriteFailure // ä¼ å…¥å¤±è´¥è¯¦æƒ…
    );

    console.log(
      `\n[Executor] âœ¨ Task Completed: Total ${totalProcessed}, Written ${totalWritten}`
    );

    return {
      success: true,
      total: totalProcessed,
      written: totalWritten,
      failed: totalFailed + finalStages.write.failed,
    };
  } catch (error: any) {
    console.error(
      `[Executor] âŒ Fatal Error: ${tenantId}:${entityType} ->`,
      error.stack || error.message
    );

    // å°è¯•æ›´æ–°æ•°æ®åº“çŠ¶æ€ä¸º failed
    try {
      await saveImportResultToDb(
        tenantId,
        entityType,
        taskTraceId,
        allCollectedRecords,
        {
          fetch: {
            total: finalStages.fetch.total,
            status: "failed",
            reason: error.message,
          },
          transform: finalStages.transform,
          write: finalStages.write,
        },
        rawDataSample,
        lastWriteFailure
      );
    } catch (dbError: any) {
      console.error(
        `[Executor] ğŸš¨ Critical: Failed to save error status to DB:`,
        dbError.message
      );
      // å¦‚æœä¿å­˜æ—¥å¿—ä¹Ÿå¤±è´¥äº†ï¼Œæˆ‘ä»¬æŠŠåŸå§‹é”™è¯¯å’Œ DB é”™è¯¯ç»„åˆä¸€ä¸‹æŠ›å‡ºï¼Œ
      // è¿™æ · BullMQ çš„ failedReason å°±èƒ½çœ‹åˆ°çœŸç›¸
      const combinedError = new Error(
        `[Original Error] ${error.message} | [DB Log Error] ${dbError.message}`
      );
      throw combinedError;
    }

    throw error;
  }
}
